{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# üïµÔ∏è Model Stealing: An Extraction Attack Demo\n",
        "\n",
        "**Core Concept**: Model extraction is a type of attack where an adversary queries a machine learning model's API to build a surrogate (replica) model. This is **IP theft through information leakage**, not database hacking.\n",
        "\n",
        "## üéØ The IP Leak Problem\n",
        "1.  Your model makes predictions continuously\n",
        "2.  Each prediction reveals information about internal decision boundaries\n",
        "3.  Attackers collect these predictions to train a replica\n",
        "4.  No need to access your training data or model weights\n",
        "5.  Result: Attacker steals years of R&D for pennies\n",
        "\n",
        "## üí∞ Economics\n",
        "-   **Small models**: ~500-1,000 queries ($0.50-$1)\n",
        "-   **Medium models**: ~5,000-10,000 queries ($5-$10)\n",
        "-   **Large models**: ~100,000+ queries ($100-$1,000)\n",
        "-   **Your development cost**: Millions of dollars\n",
        "\n",
        "## üìã Demo Scenario\n",
        "We simulate:\n",
        "1.  **Victim**: A company with a digit classifier (MNIST) API\n",
        "2.  **Attacker**: A competitor who wants to steal the model\n",
        "3.  **Attack**: Query the API and train a surrogate model\n",
        "4.  **Success**: Surrogate achieves 95%+ fidelity to the victim"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üõ†Ô∏è Step 1: Setup & Data Loading"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.datasets import load_digits\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "import seaborn as sns\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "np.random.seed(42)\n",
        "\n",
        "# Load MNIST-like digits dataset (8x8 grayscale images)\n",
        "digits = load_digits()\n",
        "X, y = digits.data, digits.target\n",
        "\n",
        "print(f\"Dataset: {X.shape[0]} samples, {X.shape[1]} features (8x8 pixels)\")\n",
        "print(f\"Classes: {np.unique(y)} (digits 0-9)\")\n",
        "\n",
        "# Split into victim's training set and holdout test set\n",
        "X_victim_train, X_test, y_victim_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.3, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "print(f\"\\nVictim training set: {X_victim_train.shape[0]} samples\")\n",
        "print(f\"Holdout test set: {X_test.shape[0]} samples\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üè¢ Step 2: Train the Victim Model (The Target)\n",
        "This represents the proprietary model that a company has spent significant resources developing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train victim model (Random Forest for demonstration)\n",
        "print(\"Training victim model (this is the IP to be stolen)...\")\n",
        "victim_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "victim_model.fit(X_victim_train, y_victim_train)\n",
        "\n",
        "# Evaluate victim model\n",
        "y_victim_pred = victim_model.predict(X_test)\n",
        "victim_accuracy = accuracy_score(y_test, y_victim_pred)\n",
        "\n",
        "print(f\"\\n‚úÖ Victim model trained!\")\n",
        "print(f\"Victim test accuracy: {victim_accuracy:.4f}\")\n",
        "print(f\"\\nThis model represents millions in R&D investment.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üîå Step 3: Simulate the API (Prediction Interface)\n",
        "In reality, this would be a REST API endpoint. Here we simulate it with a function that returns prediction probabilities."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def query_victim_api(X_queries, return_probabilities=True):\n",
        "    \"\"\"\n",
        "    Simulates querying the victim model's API.\n",
        "    \n",
        "    Args:\n",
        "        X_queries: Input samples to query\n",
        "        return_probabilities: If True, return probability vectors; else return class labels\n",
        "    \n",
        "    Returns:\n",
        "        predictions: Either probability matrix or class labels\n",
        "    \"\"\"\n",
        "    if return_probabilities:\n",
        "        # Return full probability distribution (more information leakage)\n",
        "        return victim_model.predict_proba(X_queries)\n",
        "    else:\n",
        "        # Return only class label (less information, harder to extract)\n",
        "        return victim_model.predict(X_queries)\n",
        "\n",
        "# Test the API\n",
        "sample_query = X_test[:5]\n",
        "sample_predictions = query_victim_api(sample_query)\n",
        "\n",
        "print(\"Example API Query Results (first 5 samples):\")\n",
        "print(\"Shape:\", sample_predictions.shape)\n",
        "print(\"\\nProbability distributions:\")\n",
        "print(sample_predictions)\n",
        "print(\"\\n‚ö†Ô∏è Notice: These probabilities reveal decision boundaries!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üéØ Step 4: Attacker Generates Query Dataset\n",
        "The attacker needs inputs to query. They can:\n",
        "1.  Use synthetic data (random, adversarial, or sampled from distribution)\n",
        "2.  Collect real examples from the wild\n",
        "3.  Use transfer data from similar domains\n",
        "\n",
        "Here we simulate synthetic queries."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Attacker's query budget (number of API calls they're willing to make)\n",
        "QUERY_BUDGET = 2000  # Start with 2000 queries\n",
        "\n",
        "# Strategy 1: Random synthetic queries (uniform random in feature space)\n",
        "# Note: Real attackers would use smarter strategies (active learning, etc.)\n",
        "X_attacker_queries = np.random.uniform(\n",
        "    low=X.min(), \n",
        "    high=X.max(), \n",
        "    size=(QUERY_BUDGET, X.shape[1])\n",
        ")\n",
        "\n",
        "# Strategy 2 (Optional): Mix in some real data if attacker has access\n",
        "# For demonstration, we'll add some real samples\n",
        "n_real = min(500, QUERY_BUDGET // 4)\n",
        "real_indices = np.random.choice(len(X_test), n_real, replace=False)\n",
        "X_attacker_queries[:n_real] = X_test[real_indices]\n",
        "\n",
        "print(f\"Attacker generated {QUERY_BUDGET} query samples\")\n",
        "print(f\"Query dataset shape: {X_attacker_queries.shape}\")\n",
        "print(f\"\\nEstimated cost at $0.001/query: ${QUERY_BUDGET * 0.001:.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üì° Step 5: Execute Extraction Attack (Query & Collect)\n",
        "The attacker now queries the victim API and collects predictions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"üö® ATTACK IN PROGRESS: Querying victim API...\")\n",
        "print(f\"Sending {QUERY_BUDGET} queries...\\n\")\n",
        "\n",
        "# Collect predictions from victim model\n",
        "y_attacker_soft_labels = query_victim_api(X_attacker_queries, return_probabilities=True)\n",
        "\n",
        "# The attacker now has a training dataset: (X_attacker_queries, y_attacker_soft_labels)\n",
        "print(\"‚úÖ Attack data collected!\")\n",
        "print(f\"Collected {len(y_attacker_soft_labels)} prediction vectors\")\n",
        "print(f\"Each vector contains {y_attacker_soft_labels.shape[1]} probability scores\")\n",
        "print(\"\\nAttacker now has everything needed to train a surrogate model.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ü§ñ Step 6: Train Surrogate Model (The Replica)\n",
        "Using the collected queries and predictions, the attacker trains their own model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"Training surrogate model using stolen predictions...\\n\")\n",
        "\n",
        "# Option 1: Train on hard labels (argmax of probabilities)\n",
        "y_attacker_hard_labels = y_attacker_soft_labels.argmax(axis=1)\n",
        "\n",
        "# Train surrogate (can use different architecture)\n",
        "surrogate_model = MLPClassifier(hidden_layer_sizes=(50,), max_iter=500, random_state=42)\n",
        "surrogate_model.fit(X_attacker_queries, y_attacker_hard_labels)\n",
        "\n",
        "print(\"‚úÖ Surrogate model trained!\")\n",
        "print(f\"Total extraction cost: ${QUERY_BUDGET * 0.001:.2f}\")\n",
        "print(f\"Victim's development cost: ~$1,000,000+ (estimated)\")\n",
        "print(f\"\\nROI for attacker: {1000000 / (QUERY_BUDGET * 0.001):.0f}x\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üìä Step 7: Evaluate Extraction Success\n",
        "We measure how well the surrogate replicates the victim's behavior."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Evaluate surrogate on test set\n",
        "y_surrogate_pred = surrogate_model.predict(X_test)\n",
        "y_victim_pred_test = victim_model.predict(X_test)\n",
        "\n",
        "# Metric 1: Surrogate accuracy (how well it predicts true labels)\n",
        "surrogate_accuracy = accuracy_score(y_test, y_surrogate_pred)\n",
        "\n",
        "# Metric 2: Fidelity (how often surrogate agrees with victim)\n",
        "fidelity = accuracy_score(y_victim_pred_test, y_surrogate_pred)\n",
        "\n",
        "# Metric 3: Accuracy gap\n",
        "accuracy_gap = victim_accuracy - surrogate_accuracy\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(\"EXTRACTION ATTACK RESULTS\")\n",
        "print(\"=\"*60)\n",
        "print(f\"Victim Accuracy (on true labels):     {victim_accuracy:.4f}\")\n",
        "print(f\"Surrogate Accuracy (on true labels):  {surrogate_accuracy:.4f}\")\n",
        "print(f\"Accuracy Gap:                          {accuracy_gap:.4f}\")\n",
        "print(f\"\\nüéØ Fidelity (agreement rate):          {fidelity:.4f}\")\n",
        "print(f\"\\nQueries used:                          {QUERY_BUDGET}\")\n",
        "print(f\"Cost:                                  ${QUERY_BUDGET * 0.001:.2f}\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "if fidelity > 0.90:\n",
        "    print(\"\\nüö® ATTACK SUCCESSFUL: Surrogate achieves >90% fidelity!\")\n",
        "    print(\"The victim's IP has been effectively stolen.\")\n",
        "else:\n",
        "    print(\"\\n‚ö†Ô∏è Attack partially successful. More queries may improve fidelity.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üìà Step 8: Visualize Attack Effectiveness"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create confusion matrix comparing victim vs surrogate predictions\n",
        "cm = confusion_matrix(y_victim_pred_test, y_surrogate_pred)\n",
        "\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
        "            xticklabels=range(10), yticklabels=range(10))\n",
        "plt.title(f'Victim vs Surrogate Predictions\\nFidelity: {fidelity:.2%}', fontsize=14)\n",
        "plt.ylabel('Victim Prediction', fontsize=12)\n",
        "plt.xlabel('Surrogate Prediction', fontsize=12)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"\\nDiagonal values = agreement between models\")\n",
        "print(\"Off-diagonal values = disagreements (extraction failures)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üî¨ Step 9: Query Budget Analysis\n",
        "How does extraction fidelity change with query budget?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test different query budgets\n",
        "budgets = [100, 250, 500, 1000, 2000, 5000]\n",
        "fidelities = []\n",
        "\n",
        "print(\"Testing extraction with different query budgets...\\n\")\n",
        "\n",
        "for budget in budgets:\n",
        "    # Generate queries\n",
        "    X_queries = np.random.uniform(low=X.min(), high=X.max(), size=(budget, X.shape[1]))\n",
        "    \n",
        "    # Query victim\n",
        "    y_queries = query_victim_api(X_queries, return_probabilities=True).argmax(axis=1)\n",
        "    \n",
        "    # Train surrogate\n",
        "    temp_surrogate = MLPClassifier(hidden_layer_sizes=(50,), max_iter=500, random_state=42)\n",
        "    temp_surrogate.fit(X_queries, y_queries)\n",
        "    \n",
        "    # Measure fidelity\n",
        "    temp_pred = temp_surrogate.predict(X_test)\n",
        "    temp_fidelity = accuracy_score(y_victim_pred_test, temp_pred)\n",
        "    fidelities.append(temp_fidelity)\n",
        "    \n",
        "    print(f\"Budget: {budget:5d} queries ‚Üí Fidelity: {temp_fidelity:.4f} (Cost: ${budget * 0.001:.2f})\")\n",
        "\n",
        "# Plot results\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(budgets, fidelities, marker='o', linewidth=2, markersize=8)\n",
        "plt.axhline(y=0.90, color='r', linestyle='--', label='90% Fidelity Threshold')\n",
        "plt.xlabel('Query Budget', fontsize=12)\n",
        "plt.ylabel('Extraction Fidelity', fontsize=12)\n",
        "plt.title('Model Extraction: Fidelity vs Query Budget', fontsize=14)\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(f\"\\nüí° Insight: Fidelity increases with query budget.\")\n",
        "print(f\"Even with {budgets[0]} queries (${budgets[0] * 0.001:.2f}), fidelity reaches {fidelities[0]:.2%}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üõ°Ô∏è Step 10: Defense Mechanisms (Discussion)\n",
        "\n",
        "### How to Protect Against Model Extraction:\n",
        "\n",
        "1.  **Query Limiting**: Rate limiting per user/IP\n",
        "2.  **Prediction Perturbation**: Add random noise to outputs\n",
        "3.  **Confidence Rounding**: Return rounded probabilities\n",
        "4.  **Query Analysis**: Detect suspicious patterns (e.g., grid sampling)\n",
        "5.  **Watermarking**: Embed triggers in model that reveal theft\n",
        "6.  **Output Restrictions**: Return only class labels, not probabilities\n",
        "\n",
        "### Trade-offs:\n",
        "-   Stronger defenses ‚Üí Reduced utility for legitimate users\n",
        "-   Weaker defenses ‚Üí Higher risk of IP theft\n",
        "\n",
        "This is an active area of research in ML security."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üìù Summary\n",
        "\n",
        "### What We Demonstrated:\n",
        "‚úÖ A victim model (Random Forest) was trained on proprietary data  \n",
        "‚úÖ An attacker queried the model's API {QUERY_BUDGET} times  \n",
        "‚úÖ Using only predictions, the attacker trained a surrogate model  \n",
        "‚úÖ The surrogate achieved {fidelity:.1%} fidelity to the victim  \n",
        "‚úÖ Total attack cost: ${QUERY_BUDGET * 0.001:.2f} vs millions in R&D  \n",
        "\n",
        "### Key Takeaways:\n",
        "1.  **IP Leakage**: Every prediction leaks information about your model\n",
        "2.  **Economic Threat**: Attackers can steal models for pennies on the dollar\n",
        "3.  **Silent Attack**: No database breach needed, just normal API usage\n",
        "4.  **Scale Matters**: Larger query budgets ‚Üí higher fidelity extraction\n",
        "5.  **Defense is Hard**: Protecting models without hurting usability is challenging\n",
        "\n",
        "### Real-World Impact:\n",
        "This attack has been demonstrated against:\n",
        "-   Google Prediction API\n",
        "-   Amazon ML\n",
        "-   BigML\n",
        "-   Face++ API\n",
        "-   Various commercial MLaaS platforms\n",
        "\n",
        "**Model extraction is not theoretical‚Äîit's a real threat to ML IP.**"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
